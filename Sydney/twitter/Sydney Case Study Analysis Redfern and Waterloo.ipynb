{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon, shape\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path, PureWindowsPath\n",
    "\n",
    "# Import custom functions from `scripts` folder\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from scripts.clean_tweets import geometrize_tweets, convert_shapefile_crs, find_frequencies\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "data_path = Path(\"C:/Users/emman/Box/Spring 2020/Displacement Studio/Datasets/\")\n",
    "shape_path = Path(\"C:/Users/emman/Box/Spring 2020/Displacement Studio/Shared 228 Sydney Folder/SA2 Shapefiles/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read twitter data from 2012-2016 respectively\n",
    "au12 = pd.read_csv(data_path/'au_twt2012.csv')\n",
    "au13 = pd.read_csv(data_path/'au_twt2013.csv')\n",
    "au14 = pd.read_csv(data_path/'au_twt2014.csv')\n",
    "au15 = pd.read_csv(data_path/'au_twt2015.csv')\n",
    "au16 = pd.read_csv(data_path/'au_twt2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to GeoDataFrame based on lat/lon\n",
    "au12 = geometrize_tweets(au12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "au13 = geometrize_tweets(au13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-c8b421bc4152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mau14\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeometrize_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mau14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\git\\UrbanDisplacementStudio2020\\Sydney\\work_folder\\scripts\\clean_tweets.py\u001b[0m in \u001b[0;36mgeometrize_tweets\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \"\"\"\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Create a shapely.geometry.Point for each tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mgeometry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxy\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'location.lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'location.lat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mcrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'init'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'epsg:4326'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Convert to GeoDataFrame, where each tweet's geometry is assigned to the lat/lon coords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\git\\UrbanDisplacementStudio2020\\Sydney\\work_folder\\scripts\\clean_tweets.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \"\"\"\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Create a shapely.geometry.Point for each tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mgeometry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxy\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'location.lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'location.lat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mcrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'init'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'epsg:4326'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Convert to GeoDataFrame, where each tweet's geometry is assigned to the lat/lon coords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "au14 = geometrize_tweets(au14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au15 = geometrize_tweets(au15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au16 = geometrize_tweets(au16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Australia SA2 shapefiles sa2_ucl\n",
    "syd_ucl_sa2 = gpd.read_file(shape_path/'sa2_ucl.dbf')\n",
    "# We also need to change the crs \n",
    "syd_ucl_sa2.crs = {'init': 'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syd_ucl_sa2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in case study areas \n",
    "# let's isolate the sa2s that make up our case study areas of Redfern/Waterloo, Merrickville and Maroubra\n",
    "red_wat_gdf = syd_ucl_sa2[(syd_ucl_sa2.SA2_MAIN16=='117031335')\n",
    "                          |(syd_ucl_sa2.SA2_MAIN16=='117031338')]\n",
    "\n",
    "# now let's create a simple rendition of the df so that we can combine its SA2 boundaries\n",
    "red_wat_simple = red_wat_gdf[['SA2_MAIN16','geometry', \"SA4_NAME16\"]].reset_index()\n",
    "\n",
    "# \"dissolve\" or \"aggregates\" all the polygons that share the same value for the variable we call\n",
    "red_wat_sgdf=red_wat_simple.dissolve(by=\"SA4_NAME16\")\n",
    "red_wat_sgdf.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "syd_ucl_sa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "syd_ucl_sa2.plot(ax=ax, color='gray')\n",
    "red_wat_sgdf.plot(ax=ax, color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign tracts to tweets \n",
    "We are interested in two features:\n",
    "\n",
    "   1. Whether or not a tweet is generated from our case study areas.\n",
    "   1. Whether or not a tweet is within 0.5 miles of our case study areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First case study area: Redfern/Waterloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a spatial join between tweets and redfern/waterloo\n",
    "au12_rf_cs = gpd.sjoin(au12, red_wat_sgdf, how='left', op='intersects')\n",
    "au13_rf_cs = gpd.sjoin(au13, red_wat_sgdf, how='left', op='intersects')\n",
    "au14_rf_cs = gpd.sjoin(au14, red_wat_sgdf, how='left', op='intersects')\n",
    "au15_rf_cs = gpd.sjoin(au15, red_wat_sgdf, how='left', op='intersects')\n",
    "au16_rf_cs = gpd.sjoin(au16, red_wat_sgdf, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the tweet point lies in the tract geometry, `br_diss` is not null.\n",
    "au12['redwat'] = ~au12_rf_cs['SA2_MAIN16'].isnull()\n",
    "au13['redwat'] = ~au13_rf_cs['SA2_MAIN16'].isnull()\n",
    "au14['redwat'] = ~au13_rf_cs['SA2_MAIN16'].isnull()\n",
    "au15['redwat'] = ~au13_rf_cs['SA2_MAIN16'].isnull()\n",
    "au16['redwat'] = ~au13_rf_cs['SA2_MAIN16'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{au12['redwat'].sum()} of {len(au12)} 2012 tweets are from Redfern/Waterloo\")\n",
    "print(f\"{au13['redwat'].sum()} of {len(au13)} 2013 tweets are from Redfern/Waterloo\")\n",
    "print(f\"{au14['redwat'].sum()} of {len(au14)} 2014 tweets are from Redfern/Waterloo\")\n",
    "print(f\"{au15['redwat'].sum()} of {len(au15)} 2015 tweets are from Redfern/Waterloo\")\n",
    "print(f\"{au16['redwat'].sum()} of {len(au16)} 2016 tweets are from Redfern/Waterloo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Capturing distance from Redfern/Waterloo Area\n",
    "\n",
    "Our next objective is to find tweets within 0.5 miles of Redfern/Waterloo. Instead of creating a buffer around Redfern/Waterloo, we can instead create a 0.5 mile buffer around each tweet's location, then find all tweets that overlap with the geometry of Redfern/Waterloo. The leftmost picture below illustrates this approach; we can consider the square to be the geometry of Redfern/Waterloo, and the circle to be the geometry of a single tweet.\n",
    "\n",
    "\n",
    "Each degree of latitude is approximately 69 miles apart. For longitude to miles, at a given latitude, the conversion is as follows [source](https://gis.stackexchange.com/questions/142326/calculating-longitude-length-in-miles):\n",
    "\n",
    "1 degree of longitude = cosine(latitude in decimal) * length of degree (miles) at equator\n",
    "\n",
    "Then we compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -33.9 is roughly the median latitude of Redfern/Waterloo\n",
    "np.cos(-33.905) * 69.172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 degree of latitude is 69 miles, and 1 degree of longitude is 54.9610 miles. This means that 0.5 miles is represented by $\\frac{0.5}{69} \\approx 0.007246$ degrees of latitude and $\\frac{0.5}{54.9610} \\approx 0.009097$ degrees of longitude. A roughly 0.5 mile buffer can be established by creating a buffer of ~0.009 degrees around each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 0.009\n",
    "\n",
    "# Build dataframe containing buffer around each tweet\n",
    "au12_buffer, au13_buffer, au14_buffer, au15_buffer, au16_buffer = au12.copy(), au13.copy(), au14.copy(), au15.copy(), au16.copy()\n",
    "au12_buffer['geometry'] = au12_buffer.buffer(BUFFER)\n",
    "au13_buffer['geometry'] = au13_buffer.buffer(BUFFER)\n",
    "au14_buffer['geometry'] = au14_buffer.buffer(BUFFER)\n",
    "au15_buffer['geometry'] = au15_buffer.buffer(BUFFER)\n",
    "au16_buffer['geometry'] = au16_buffer.buffer(BUFFER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing distance from Redfern/Waterloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a spatial join between tweets and redfern/waterloo + buffer\n",
    "au12_bufjoin_rw = gpd.sjoin(au12_buffer, red_wat_sgdf, how='left', op='intersects')\n",
    "au13_bufjoin_rw = gpd.sjoin(au13_buffer, red_wat_sgdf, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au14_bufjoin_rw = gpd.sjoin(au14_buffer, red_wat_sgdf, how='left', op='intersects')\n",
    "au15_bufjoin_rw = gpd.sjoin(au15_buffer, red_wat_sgdf, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au16_bufjoin_rw = gpd.sjoin(au16_buffer, red_wat_sgdf, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the tweet buffer intersects the tract geometry, `br_diss` is not null.\n",
    "au12['buffer'] = ~au12_bufjoin_rw['SA2_MAIN16'].isnull()\n",
    "au13['buffer'] = ~au13_bufjoin_rw['SA2_MAIN16'].isnull()\n",
    "au14['buffer'] = ~au14_bufjoin_rw['SA2_MAIN16'].isnull()\n",
    "au15['buffer'] = ~au15_bufjoin_rw['SA2_MAIN16'].isnull()\n",
    "au16['buffer'] = ~au16_bufjoin_rw['SA2_MAIN16'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one expanded tweet (blue), one regular tweet (red):\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "syd_ucl_sa2.plot(ax=ax, color='gray')\n",
    "au16_buffer.sample(n=1).plot(ax=ax, color='blue')\n",
    "au13.sample(n=1).plot(ax=ax, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(au12['buffer'] & ~au12['redwat']).sum()} of {len(au12)} 2012 tweets are from the buffer\")\n",
    "print(f\"{(au13['buffer'] & ~au13['redwat']).sum()} of {len(au13)} 2013 tweets are from the buffer\")\n",
    "print(f\"{(au14['buffer'] & ~au14['redwat']).sum()} of {len(au14)} 2013 tweets are from the buffer\")\n",
    "print(f\"{(au15['buffer'] & ~au15['redwat']).sum()} of {len(au15)} 2013 tweets are from the buffer\")\n",
    "print(f\"{(au16['buffer'] & ~au16['redwat']).sum()} of {len(au16)} 2013 tweets are from the buffer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capturing distance for Marrickville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add hour for future analysis\n",
    "# au12['hour'] = pd.to_datetime(au12['created_at'] // 1000, unit='s').dt.hour\n",
    "# au13['hour'] = pd.to_datetime(au13['created_at'] // 1000, unit='s').dt.hour\n",
    "# au14['hour'] = pd.to_datetime(au14['created_at'] // 1000, unit='s').dt.hour\n",
    "# au15['hour'] = pd.to_datetime(au15['created_at'] // 1000, unit='s').dt.hour\n",
    "# au16['hour'] = pd.to_datetime(au16['created_at'] // 1000, unit='s').dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of derogatory words for Aboriginal people frequencies\n",
    "\n",
    "We first observe all tweets (regardless of timestamp). For , to avoid any overlap with other words, we check for two patterns:\n",
    "\n",
    "\n",
    "We also make our analysis case-insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All tweets sent from Redfern/Waterloo\n",
    "# print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"abo\"'.format(\n",
    "#     *find_frequencies(au12.loc[au12['redwat'], 'text'], r'abo')))\n",
    "\n",
    "# print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"abbo \"'.format(\n",
    "#     *find_frequencies(au12.loc[au12['redwat'], 'text'], r'abbo')))\n",
    "\n",
    "# print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"boong\"'.format(\n",
    "#     *find_frequencies(au12.loc[au12['redwat'], 'text'], r'boong')))\n",
    "\n",
    "# print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"bung \"'.format(\n",
    "#     *find_frequencies(au12.loc[au12['redwat'], 'text'], r'bung')))\n",
    "\n",
    "# print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"coon \"'.format(\n",
    "#     *find_frequencies(au12.loc[au12['redwat'], 'text'], r'coon')))\n",
    "\n",
    "# print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"lubra\"'.format(\n",
    "#     *find_frequencies(au12.loc[au12['redwat'], 'text'], r'lubra')))\n",
    "\n",
    "# print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"gin \"'.format(\n",
    "#     *find_frequencies(au12.loc[au12['redwat'], 'text'], r'gin')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"Redfern\"'.format(\n",
    "    *find_frequencies(au12.loc[au12['redwat'], 'text'], r'redfern')))\n",
    "\n",
    "print('{} of {} tweets sent from Redfern/Waterloo in 2012 contain \"Waterloo\"'.format(\n",
    "    *find_frequencies(au12.loc[au12['redwat'], 'text'], r'waterloo')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
